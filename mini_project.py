import streamlit as st
import random
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import joblib
import folium
import plotly.express as px
from streamlit_folium import st_folium
# Load the model
model = joblib.load("model.joblib")

# List of stopwords
stopwords = ["‡∏ú‡∏π‡πâ", "‡∏ó‡∏µ‡πà", "‡∏ã‡∏∂‡πà‡∏á", "‡∏≠‡∏±‡∏ô"]

# Streamlit UI
st.title('Address Detection Visualization')
#st.markdown('------------------------------------')
# Description
# Description
st.markdown("""
    <div style='border: 1px solid black; padding: 10px; border-radius: 5px; background-color: #F9F9F9;'>
           üìä Visualization ‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ñ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏•‡∏µ‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ - ‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Å‡∏≤‡∏£‡πÉ‡∏™‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ<br> 
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏ó‡∏£‡∏≤‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á
    </div>
""", unsafe_allow_html=True)

st.markdown('------------------------------------')
# Feature extraction function
def tokens_to_features(tokens, i):
    word = tokens[i]
    features = {
        "bias": 1.0,
        "word.word": word,
        "word[:3]": word[:3],
        "word.isspace()": word.isspace(),
        "word.is_stopword()": word in stopwords,
        "word.isdigit()": word.isdigit(),
        "word.islen5": word.isdigit() and len(word) == 5
    }
    if i > 0:
        prevword = tokens[i - 1]
        features.update({
            "-1.word.prevword": prevword,
            "-1.word.isspace()": prevword.isspace(),
            "-1.word.is_stopword()": prevword in stopwords,
            "-1.word.isdigit()": prevword.isdigit(),
        })
    else:
        features["BOS"] = True
    if i < len(tokens) - 1:
        nextword = tokens[i + 1]
        features.update({
            "+1.word.nextword": nextword,
            "+1.word.isspace()": nextword.isspace(),
            "+1.word.is_stopword()": nextword in stopwords,
            "+1.word.isdigit()": nextword.isdigit(),
        })
    else:
        features["EOS"] = True
    return features

# Parsing function
def parse(text):
    tokens = text.split()
    features = [tokens_to_features(tokens, i) for i in range(len(tokens))]
    return model.predict([features])[0]

# Province list for multi-select
provinces = [
    "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û", "‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£", "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï"
]


# List of provinces in Thailand with coordinates
province_coords = {
    "‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û": (13.7563, 100.5018),
    "‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ": (13.8621, 100.5144),
    "‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ": (14.0200, 100.5250),
    "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£": (13.5991, 100.5990),
    "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ": (13.3611, 100.9847),
    "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà": (18.7883, 98.9853),
    "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï": (7.8804, 98.3923),
    "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡∏£‡∏≤‡∏¢": (19.9100, 99.8400),
    "‡∏•‡∏≥‡∏û‡∏π‡∏ô": (18.5800, 99.0000),
    "‡∏•‡∏≥‡∏õ‡∏≤‡∏á": (18.2888, 99.4900),
    "‡πÅ‡∏û‡∏£‡πà": (18.1317, 100.2024),
    "‡∏ô‡πà‡∏≤‡∏ô": (18.7833, 100.7836),
    "‡∏≠‡∏∏‡∏ï‡∏£‡∏î‡∏¥‡∏ï‡∏ñ‡πå": (17.6238, 100.0993),
    "‡∏ï‡∏≤‡∏Å": (16.8791, 99.1256),
    "‡∏™‡∏∏‡πÇ‡∏Ç‡∏ó‡∏±‡∏¢": (17.0148, 99.8260),
    "‡∏û‡∏¥‡∏©‡∏ì‡∏∏‡πÇ‡∏•‡∏Å": (16.8219, 100.2659),
    "‡∏û‡∏¥‡∏à‡∏¥‡∏ï‡∏£": (16.4422, 100.3480),
    "‡∏Å‡∏≥‡πÅ‡∏û‡∏á‡πÄ‡∏û‡∏ä‡∏£": (16.4720, 99.5210),
    "‡∏ô‡∏Ñ‡∏£‡∏™‡∏ß‡∏£‡∏£‡∏Ñ‡πå": (15.7007, 100.1372),
    "‡∏≠‡∏∏‡∏ó‡∏±‡∏¢‡∏ò‡∏≤‡∏ô‡∏µ": (15.3829, 100.0269),
    "‡∏ä‡∏±‡∏¢‡∏ô‡∏≤‡∏ó": (15.1877, 100.1253),
    "‡∏•‡∏û‡∏ö‡∏∏‡∏£‡∏µ": (14.7995, 100.6534),
    "‡∏™‡∏¥‡∏á‡∏´‡πå‡∏ö‡∏∏‡∏£‡∏µ": (14.8911, 100.3984),
    "‡∏≠‡πà‡∏≤‡∏á‡∏ó‡∏≠‡∏á": (14.5896, 100.4526),
    "‡∏û‡∏£‡∏∞‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏≠‡∏¢‡∏∏‡∏ò‡∏¢‡∏≤": (14.3704, 100.5853),
    "‡∏™‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏µ": (14.5289, 100.9109),
    "‡∏ô‡∏Ñ‡∏£‡∏ô‡∏≤‡∏¢‡∏Å": (14.2061, 101.2135),
    "‡∏â‡∏∞‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏ó‡∏£‡∏≤": (13.6904, 101.0762),
    "‡∏õ‡∏£‡∏≤‡∏à‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ": (14.0516, 101.3682),
    "‡∏™‡∏£‡∏∞‡πÅ‡∏Å‡πâ‡∏ß": (13.8240, 102.0644),
    "‡∏£‡∏∞‡∏¢‡∏≠‡∏á": (12.6827, 101.2570),
    "‡∏à‡∏±‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ": (12.6077, 102.1110),
    "‡∏ï‡∏£‡∏≤‡∏î": (12.2438, 102.5156),
    "‡∏Å‡∏≤‡∏ç‡∏à‡∏ô‡∏ö‡∏∏‡∏£‡∏µ": (14.0041, 99.5483),
    "‡∏£‡∏≤‡∏ä‡∏ö‡∏∏‡∏£‡∏µ": (13.5360, 99.8177),
    "‡πÄ‡∏û‡∏ä‡∏£‡∏ö‡∏∏‡∏£‡∏µ": (13.1111, 99.9391),
    "‡∏õ‡∏£‡∏∞‡∏à‡∏ß‡∏ö‡∏Ñ‡∏µ‡∏£‡∏µ‡∏Ç‡∏±‡∏ô‡∏ò‡πå": (11.8115, 99.7970),
    "‡∏ô‡∏Ñ‡∏£‡∏õ‡∏ê‡∏°": (13.8198, 100.0638),
    "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏≤‡∏Ñ‡∏£": (13.5472, 100.2744),
    "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°": (13.4115, 100.0005),
    "‡∏™‡∏∏‡∏û‡∏£‡∏£‡∏ì‡∏ö‡∏∏‡∏£‡∏µ": (14.4753, 100.1160),
    "‡∏Å‡∏≤‡∏¨‡∏™‡∏¥‡∏ô‡∏ò‡∏∏‡πå": (16.4338, 103.5062),
    "‡∏Ç‡∏≠‡∏ô‡πÅ‡∏Å‡πà‡∏ô": (16.4322, 102.8236),
    "‡∏ä‡∏±‡∏¢‡∏†‡∏π‡∏°‡∏¥": (15.8057, 102.0310),
    "‡∏ô‡∏Ñ‡∏£‡∏û‡∏ô‡∏°": (17.4098, 104.7784),
    "‡∏ô‡∏Ñ‡∏£‡∏£‡∏≤‡∏ä‡∏™‡∏µ‡∏°‡∏≤": (15.0000, 102.1167),
    "‡∏ö‡∏∏‡∏£‡∏µ‡∏£‡∏±‡∏°‡∏¢‡πå": (14.9930, 103.1029),
    "‡∏°‡∏´‡∏≤‡∏™‡∏≤‡∏£‡∏Ñ‡∏≤‡∏°": (16.1808, 103.3000),
    "‡∏°‡∏∏‡∏Å‡∏î‡∏≤‡∏´‡∏≤‡∏£": (16.5453, 104.7233),
    "‡∏¢‡πÇ‡∏™‡∏ò‡∏£": (15.7944, 104.1452),
    "‡∏£‡πâ‡∏≠‡∏¢‡πÄ‡∏≠‡πá‡∏î": (16.0527, 103.6530),
    "‡∏®‡∏£‡∏µ‡∏™‡∏∞‡πÄ‡∏Å‡∏©": (15.1184, 104.3299),
    "‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£": (17.1552, 104.1388),
    "‡∏™‡∏∏‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå": (14.8832, 103.4935),
    "‡∏´‡∏ô‡∏≠‡∏á‡∏Ñ‡∏≤‡∏¢": (17.8782, 102.7421),
    "‡∏´‡∏ô‡∏≠‡∏á‡∏ö‡∏±‡∏ß‡∏•‡∏≥‡∏†‡∏π": (17.2046, 102.4404),
    "‡∏≠‡∏∏‡∏î‡∏£‡∏ò‡∏≤‡∏ô‡∏µ": (17.4138, 102.7874),
    "‡∏≠‡∏∏‡∏ö‡∏•‡∏£‡∏≤‡∏ä‡∏ò‡∏≤‡∏ô‡∏µ": (15.2444, 104.8475),
    "‡∏≠‡∏≥‡∏ô‡∏≤‡∏à‡πÄ‡∏à‡∏£‡∏¥‡∏ç": (15.8683, 104.6283),
    "‡∏¢‡∏∞‡∏•‡∏≤": (6.5400, 101.2800),
    "‡∏õ‡∏±‡∏ï‡∏ï‡∏≤‡∏ô‡∏µ": (6.8689, 101.2501),
    "‡∏ô‡∏£‡∏≤‡∏ò‡∏¥‡∏ß‡∏≤‡∏™": (6.4254, 101.8253),
    "‡∏™‡∏ï‡∏π‡∏•": (6.6237, 100.0673),
    "‡∏™‡∏á‡∏Ç‡∏•‡∏≤": (7.1894, 100.5951),
    "‡∏û‡∏±‡∏ó‡∏•‡∏∏‡∏á": (7.6173, 100.0802),
    "‡∏ï‡∏£‡∏±‡∏á": (7.5580, 99.6117),
    "‡∏ô‡∏Ñ‡∏£‡∏®‡∏£‡∏µ‡∏ò‡∏£‡∏£‡∏°‡∏£‡∏≤‡∏ä": (8.4304, 99.9631),
    "‡∏Å‡∏£‡∏∞‡∏ö‡∏µ‡πà": (8.0863, 98.9063),
    "‡∏û‡∏±‡∏á‡∏á‡∏≤": (8.4510, 98.5310),
    "‡∏™‡∏∏‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ò‡∏≤‡∏ô‡∏µ": (9.1416, 99.3296),
    "‡∏ä‡∏∏‡∏°‡∏û‡∏£": (10.4959, 99.1800)
}

provinces = list(province_coords.keys())

# Streamlit multi-select for provinces
selected_provinces = st.multiselect(
    "‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î",
    provinces,
    default=["‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û", "‡∏ô‡∏ô‡∏ó‡∏ö‡∏∏‡∏£‡∏µ", "‡∏õ‡∏ó‡∏∏‡∏°‡∏ò‡∏≤‡∏ô‡∏µ", "‡∏™‡∏°‡∏∏‡∏ó‡∏£‡∏õ‡∏£‡∏≤‡∏Å‡∏≤‡∏£", "‡∏ä‡∏•‡∏ö‡∏∏‡∏£‡∏µ", "‡πÄ‡∏ä‡∏µ‡∏¢‡∏á‡πÉ‡∏´‡∏°‡πà", "‡∏†‡∏π‡πÄ‡∏Å‡πá‡∏ï"]
)

# Function to create a map and highlight selected provinces
def create_map(selected_provinces):
    # Initialize map centered in Thailand
    m = folium.Map(location=[13.736717, 100.523186], zoom_start=6)

    # Add markers for selected provinces
    for province in selected_provinces:
        if province in province_coords:
            folium.Marker(
                location=province_coords[province],
                popup=f"{province}",
                icon=folium.Icon(color="blue", icon="info-sign")
            ).add_to(m)
    
    return m

# Display the map
st.markdown("### ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å")
province_map = create_map(selected_provinces)
st_folium(province_map, width=800, height=600)

# Address format options with "No prefix" set as the default
format_options = {
    "‡∏ä‡∏∑‡πà‡∏≠": ["‡∏ô‡∏≤‡∏¢", "‡∏ô‡∏≤‡∏á", "‡∏ô‡∏≤‡∏á‡∏™‡∏≤‡∏ß","‡∏î.‡∏ä.","‡∏î.‡∏ç.", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô": ["‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô", "‡∏°.", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏ã‡∏≠‡∏¢": ["‡∏ã‡∏≠‡∏¢", "‡∏ã.", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏ñ‡∏ô‡∏ô": ["‡∏ñ‡∏ô‡∏ô", "‡∏ñ.", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏ï‡∏≥‡∏ö‡∏•": ["‡∏ï‡∏≥‡∏ö‡∏•", "‡∏ï.", "‡πÅ‡∏Ç‡∏ß‡∏á", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠": ["‡∏≠‡∏≥‡πÄ‡∏†‡∏≠", "‡∏≠.", "‡πÄ‡∏Ç‡∏ï", "‡πÑ‡∏°‡πà‡∏°‡∏µ"],
    "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î": ["‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏à.", "‡πÑ‡∏°‡πà‡∏°‡∏µ"]
}

# Set "No prefix" as the default for all components
selected_formats = {
    key: st.multiselect(
        f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤ {key}",
        options,
        default=["‡πÑ‡∏°‡πà‡∏°‡∏µ"] if "‡πÑ‡∏°‡πà‡∏°‡∏µ" in options else []
    )
    for key, options in format_options.items()
}

# Mock data for other components
first_names = ["‡∏™‡∏°‡∏ä‡∏≤‡∏¢", "‡∏™‡∏°‡∏´‡∏ç‡∏¥‡∏á", "‡∏ß‡∏£‡∏û‡∏•", "‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‡πÄ‡∏û‡πá‡∏ç","‡πÄ‡∏Ç‡πá‡∏°‡∏Å‡∏•‡∏±‡∏î", "‡∏Å‡∏£‡∏Å‡∏≤‡∏£", "‡πÄ‡∏ó‡∏¥‡∏î‡∏ó‡∏π‡∏•", "‡πÄ‡∏î‡πà‡∏ô‡∏ä‡∏±‡∏î"]
village_variants = ["‡∏™‡∏∏‡∏Ç‡∏™‡∏±‡∏ô‡∏ï‡πå", "‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á","‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏û‡∏ä‡∏£", "‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥", "‡∏ö‡πâ‡∏≤‡∏ô‡∏£‡πà‡∏°‡∏£‡∏∑‡πà‡∏ô", "‡∏ö‡πâ‡∏≤‡∏ô‡∏ü‡πâ‡∏≤‡πÉ‡∏™"]
soi_variants = ["‡πÇ‡∏ä‡∏Ñ‡∏ä‡∏±‡∏¢", "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏ô‡∏Ñ‡∏£", "‡∏™‡∏∏‡∏Ç‡∏™‡∏°‡πÉ‡∏à", "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏£‡∏∏‡πà‡∏á‡πÄ‡∏£‡∏∑‡∏≠‡∏á", "‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà", "‡∏™‡∏∏‡∏Ç‡πÉ‡∏à", "‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡∏ô‡∏Ñ‡∏£"]
road_variants = ["‡∏ö‡∏≤‡∏á‡∏ô‡∏≤-‡∏ï‡∏£‡∏≤‡∏î", "‡πÄ‡∏û‡∏ä‡∏£‡πÄ‡∏Å‡∏©‡∏°","‡πÄ‡∏û‡∏ä‡∏£‡πÄ‡∏Å‡∏©‡∏°", "‡∏™‡∏∏‡∏Ç‡∏∏‡∏°‡∏ß‡∏¥‡∏ó", "‡∏£‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏´‡∏á"]
subdistrict_variants = ["‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å‡∏ô‡πâ‡∏≠‡∏¢", "‡∏ö‡∏≤‡∏á‡∏Å‡∏≠‡∏Å‡πÉ‡∏´‡∏ç‡πà", "‡∏ò‡∏ô‡∏ö‡∏∏‡∏£‡∏µ", "‡∏ö‡∏≤‡∏á‡∏û‡∏•‡∏±‡∏î"]
district_variants = ["‡∏Ñ‡∏•‡∏≠‡∏á‡∏™‡∏≤‡∏ô", "‡∏õ‡∏ó‡∏∏‡∏°‡∏ß‡∏±‡∏ô","‡∏£‡∏≤‡∏©‡∏é‡∏£‡πå‡∏ö‡∏π‡∏£‡∏ì‡∏∞", "‡∏î‡∏∏‡∏™‡∏¥‡∏ï","‡∏û‡∏ç‡∏≤‡πÑ‡∏ó", "‡∏ö‡∏≤‡∏á‡∏£‡∏±‡∏Å", "‡∏°‡∏µ‡∏ô‡∏ö‡∏∏‡∏£‡∏µ"]
province_variants = selected_provinces if selected_provinces else provinces
postal_codes = ["10110", "10230" ,"20000", "10200", "10210", "10220", "10230",
    "10300", "10310""21000","30000",  # Nakhon Ratchasima
    "40000",  # Khon Kaen
    "50000",  # Chiang Mai
    "60000",  # Nakhon Sawan
    "70000",  # Ratchaburi
    "80000",  # Nakhon Si Thammarat
    "90000",  # Songkhla
    "91000",  # Satun
    "92000",  # Trang
    "93000",  # Phatthalung
    "94000",  # Pattani
    "96000",  # Narathiwat
    "97000",  ]

# Generate a random address
def generate_address(selected_formats):
    def format_component(format_key, variants):
        selected_format = random.choice(selected_formats[format_key]) if selected_formats[format_key] else ""
        return f"{selected_format}{random.choice(variants)}" if selected_format != "‡πÑ‡∏°‡πà‡∏°‡∏µ" else random.choice(variants)

    # Handle House Number directly
    house_number = random.choice(["553", "456/78", "99/1", "123‡∏´‡∏°‡∏π‡πà1","88/22", "234", "5/3", "12", "900‡∏´‡∏°‡∏π‡πà12", "101",
    "74/11", "87‡∏´‡∏°‡∏π‡πà3", "55‡∏´‡∏°‡∏π‡πà9"])

    return {
        "‡∏ä‡∏∑‡πà‡∏≠": format_component("‡∏ä‡∏∑‡πà‡∏≠", first_names),
        "‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà": house_number,
        "‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô": format_component("‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô", village_variants),
        "‡∏ã‡∏≠‡∏¢": format_component("‡∏ã‡∏≠‡∏¢", soi_variants),
        "‡∏ñ‡∏ô‡∏ô": format_component("‡∏ñ‡∏ô‡∏ô", road_variants),
        "‡∏ï‡∏≥‡∏ö‡∏•": format_component("‡∏ï‡∏≥‡∏ö‡∏•", subdistrict_variants),
        "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠": format_component("‡∏≠‡∏≥‡πÄ‡∏†‡∏≠", district_variants),
        "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î": format_component("‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", province_variants),
        "‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå": random.choice(postal_codes)
    }

# Generate address samples
def generate_samples(selected_formats, num_samples=50):
    sample_addresses = []
    predicted_tags_list = []
    label_list = []

    # Tag labels for components
    tag_labels = {
        "‡∏ä‡∏∑‡πà‡∏≠": "O",
        "‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà": "ADDR",
        "‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô": "ADDR",
        "‡∏ã‡∏≠‡∏¢": "ADDR",
        "‡∏ñ‡∏ô‡∏ô": "ADDR",
        "‡∏ï‡∏≥‡∏ö‡∏•": "LOC",
        "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠": "LOC",
        "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î": "LOC",
        "‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå": "POST"
    }

    # Define the components order and visibility
    components_order = ["‡∏ä‡∏∑‡πà‡∏≠", "‡∏ö‡πâ‡∏≤‡∏ô‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà", "‡∏´‡∏°‡∏π‡πà‡∏ö‡πâ‡∏≤‡∏ô", "‡∏ã‡∏≠‡∏¢", "‡∏ñ‡∏ô‡∏ô", "‡∏ï‡∏≥‡∏ö‡∏•", "‡∏≠‡∏≥‡πÄ‡∏†‡∏≠", "‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î", "‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå"]
    component_visibility = {component: True for component in components_order}  # Default: all visible

    for _ in range(num_samples):
        # Generate random address data
        address_data = generate_address(selected_formats)
        customized_address = " ".join([
            address_data[component]
            for component in components_order
            if component_visibility.get(component, False)
        ])

        # Collect labels based on components
        labels = [
            tag_labels[component]
            for component in components_order
            if component_visibility.get(component, False)
        ]

        # Use the `parse` function to generate predictions
        predicted_tags = parse(customized_address)  # Assume parse function returns list of tags matching words in the address

        # Append data to respective lists
        sample_addresses.append(customized_address)
        predicted_tags_list.append(predicted_tags)
        label_list.append(labels)

    return sample_addresses, predicted_tags_list, label_list

# Display samples and generate confusion matrix
# Generate and display all charts
if st.button("Generate All Charts"):
    # Generate Samples
    samples, predictions, labels = generate_samples(selected_formats)
    
    # Create DataFrame
    df_addresses = pd.DataFrame({
        "Address ": samples,
        "Predict": predictions,
        "Labels": labels,
    })
    st.dataframe(df_addresses)  # Display the DataFrame

    st.markdown("""
    <div style='border: 1px solid #000; padding: 10px; border-radius: 10px; background-color: #F5F5F5; font-family: Arial, sans-serif;'>
        <b>     LOC</b> >> ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô ‡∏ï‡∏≥‡∏ö‡∏• ‡∏≠‡∏≥‡πÄ‡∏†‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î <br>
        <b>     POST</b> >> ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏©‡∏ì‡∏µ‡∏¢‡πå <br>
        <b>     ADDR</b> >> ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà <br>
        <b>     O</b> >> ‡∏´‡∏°‡∏≤‡∏¢‡∏ñ‡∏∂‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÅ‡∏ö‡∏ö‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà
    </div>
""", unsafe_allow_html=True)
    st.markdown('------------------------------------')
    # Flatten Labels and Predictions for analysis
    flat_labels = [tag for sublist in df_addresses["Labels"] for tag in sublist]
    flat_predictions = [tag for sublist in df_addresses["Predict"] for tag in sublist]
    
    # Confusion Matrix
    # Confusion Matrix
    def create_confusion_matrix(true_labels, predicted_labels):
        labels = ["O", "LOC", "POST", "ADDR"]  # Define label categories
        cm = confusion_matrix(true_labels, predicted_labels, labels=labels)
        return pd.DataFrame(cm, index=labels, columns=labels)

    cm_df = create_confusion_matrix(flat_labels, flat_predictions)
    fig, ax = plt.subplots(figsize=(8, 6))
    #sns.heatmap(cm_df, annot=True, fmt="d", cmap="Blues", linecolor="white", linewidths=0.5, ax=ax)
    ax.set_xlabel("Predict", fontsize=12)
    ax.set_ylabel("Label", fontsize=12)
    #st.pyplot(fig)

    # Sentence-Level Prediction Patterns Bar Chart
    sentence_patterns = [" ".join(pred) for pred in df_addresses["Predict"]]
    pattern_counts = pd.Series(sentence_patterns).value_counts().reset_index()
    pattern_counts.columns = ['Pattern', 'Count']
    pattern_counts = pattern_counts.sort_values(by="Count", ascending=True)
    # Prediction Sentence Patterns
    st.markdown("### Prediction Sentence Patterns")
    fig = px.bar(
        pattern_counts,
        x="Count",
        y="Pattern",
        orientation='h',
        #title="Frequency of Prediction Patterns",
        labels={"Count": "Count", "Pattern": "Prediction Pattern"}
    )
    st.plotly_chart(fig, use_container_width=True)

    # Match Comparison Chart
    # Match Comparison Chart
    comparison_df = pd.DataFrame({
        "Label": flat_labels,
        "Predict": flat_predictions
    })
    comparison_df["Match"] = comparison_df["Label"] == comparison_df["Predict"]

    # Count matches and mismatches
    comparison_counts = comparison_df.groupby(["Label", "Match"]).size().reset_index(name="Count")
    comparison_pivot = comparison_counts.pivot(index="Label", columns="Match", values="Count").fillna(0)
    comparison_pivot.columns = ["Incorrect", "Correct"]  # Update column names
    comparison_pivot = comparison_pivot.reset_index()

    st.markdown("### Prediction Comparison Chart")
    comparison_melted = comparison_pivot.melt(id_vars="Label", var_name="Match Type", value_name="Count")

    # Define color scheme alternating "Correct" and "Incorrect"
    custom_colors = {
        "Correct": "#0068C9",  # Same blue color as in the original chart
        "Incorrect": "#83C9FF"  # Same orange color as in the original chart
    }

    fig = px.bar(
        comparison_melted,
        x="Label",
        y="Count",
        color="Match Type",
        color_discrete_map=custom_colors,  # Apply custom colors
        barmode="stack",
        labels={"Label": "Label", "Count": "Count", "Match Type": "Match Type"}
    )

    # Sort bars to alternate "Correct" and "Incorrect"
    fig.for_each_trace(lambda trace: trace.update(name="Correct" if trace.name == "Correct" else "Incorrect"))
    fig.data = sorted(fig.data, key=lambda x: x.name, reverse=False)  # Ensure alternating stacking

    # Plotly chart
    st.plotly_chart(fig, use_container_width=True)
    st.markdown("###### ‡∏Å‡∏£‡∏≤‡∏ü‡∏ô‡∏µ‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ó‡∏µ‡πà‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ")
    # Component-wise Correct/Incorrect Summary
    st.markdown("#### Component of Address (Correct vs Incorrect)")
    components_order = ["Name", "HouseNumber", "Village", "Soi", "Road", "Subdistrict", "District", "Province", "PostalCode"]
    component_summary = []

    # Analyze correct and incorrect counts for each component
    for i, component in enumerate(components_order):
        correct_count = 0
        incorrect_count = 0
        for pred, label in zip(predictions, labels):
            if i < len(pred) and i < len(label):  # Avoid index errors
                if pred[i] == label[i]:
                    correct_count += 1
                else:
                    incorrect_count += 1
        component_summary.append({"Component": component, "Correct": correct_count, "Incorrect": incorrect_count})

    # Convert to DataFrame for visualization
    summary_df = pd.DataFrame(component_summary)

    # Create an interactive bar chart using Plotly
    fig = px.bar(
        summary_df.melt(id_vars="Component", var_name="Type", value_name="Count"),
        x="Component",
        y="Count",
        color="Type",
        barmode="stack",
        #title="Component-Wise Correct vs Incorrect Count",
        labels={"Component": "Component", "Count": "Count", "Type": "Type"}
    )

    # Display the interactive chart
    st.plotly_chart(fig, use_container_width=True)

    # Display the summary table
    st.dataframe(summary_df.reset_index(drop=True), use_container_width=True)
